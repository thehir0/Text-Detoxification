{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format. T5 works well on a variety of tasks out-of-the-box by prepending a different prefix to the input corresponding to each task, e.g., for translation: translate English to German: …, for summarization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 't5-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from willbedeleted.make_dataset import FilteredDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = FilteredDataset(test=False)\n",
    "test_dataset = FilteredDataset(test=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get rid off the toxicity classificator, since our future model will handle this itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9829/9829 [00:00<00:00, 26908.18it/s]\n",
      "100%|██████████| 518/518 [00:00<00:00, 28004.20it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = {'text': [], 'label': []}\n",
    "test_data = {'text': [], 'label': []}\n",
    "\n",
    "for batch, labels in tqdm(train_dataloader):\n",
    "    batch = list(batch)\n",
    "    labels = list(labels)\n",
    "    train_data['text'].extend(batch)\n",
    "    train_data['label'].extend(labels)\n",
    "\n",
    "for batch, labels in tqdm(test_dataloader):\n",
    "    batch = list(batch)\n",
    "    labels = list(labels)\n",
    "    test_data['text'].extend(batch)\n",
    "    test_data['label'].extend(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split to validation and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 16554\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'label'],\n",
       "         num_rows: 251612\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'label'],\n",
       "         num_rows: 62903\n",
       "     })\n",
       " }))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_data).train_test_split(test_size=0.2, seed=42)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "test_dataset, train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    text_tokens = tokenizer(example['text'], padding='max_length', truncation=True, max_length=128)\n",
    "    label_tokens = tokenizer(example['label'], padding='max_length', truncation=True, max_length=128)\n",
    "    \n",
    "    text_tokens[\"labels\"] = label_tokens[\"input_ids\"]\n",
    "    \n",
    "    return text_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 251612/251612 [00:40<00:00, 6232.33 examples/s]\n",
      "Map: 100%|██████████| 62903/62903 [00:09<00:00, 6904.04 examples/s]\n",
      "Map: 100%|██████████| 16554/16554 [00:02<00:00, 8118.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_traindataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_testdataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_traindataset = tokenized_traindataset.remove_columns(['text', 'label'])\n",
    "tokenized_traindataset = tokenized_traindataset.with_format(\"torch\")\n",
    "\n",
    "tokenized_testdataset = tokenized_testdataset.remove_columns(['text', 'label'])\n",
    "tokenized_testdataset = tokenized_testdataset.with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Why didn't you destroy all of them?\", \"why didn't you destroy everyone?\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tokenizer.decode(tokenized_traindataset['test'][0]['input_ids'], skip_special_tokens=True,temperature=0),\n",
    "tokenizer.decode(tokenized_traindataset['test'][0]['labels'], skip_special_tokens=True,temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 160\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    report_to='tensorboard',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metric.metric import calculate_metric\n",
    "def compute_metric(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    return calculate_metric(decoded_labels, decoded_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7865' max='7865' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7865/7865 1:56:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Sim</th>\n",
       "      <th>Fl</th>\n",
       "      <th>J</th>\n",
       "      <th>Blue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.626425</td>\n",
       "      <td>0.706339</td>\n",
       "      <td>0.822377</td>\n",
       "      <td>0.369215</td>\n",
       "      <td>0.499427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>0.193629</td>\n",
       "      <td>0.658840</td>\n",
       "      <td>0.715029</td>\n",
       "      <td>0.829025</td>\n",
       "      <td>0.397430</td>\n",
       "      <td>0.509289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.189763</td>\n",
       "      <td>0.678553</td>\n",
       "      <td>0.718720</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>0.412158</td>\n",
       "      <td>0.514119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>0.187898</td>\n",
       "      <td>0.685357</td>\n",
       "      <td>0.720615</td>\n",
       "      <td>0.831987</td>\n",
       "      <td>0.418187</td>\n",
       "      <td>0.516174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.187309</td>\n",
       "      <td>0.689156</td>\n",
       "      <td>0.720980</td>\n",
       "      <td>0.832544</td>\n",
       "      <td>0.420949</td>\n",
       "      <td>0.516778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on cuda\n",
      "Calculating style of predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1966/1966 [01:19<00:00, 24.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU similarity\n",
      "Calculating similarity by Wieting subword-embedding SIM model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1966/1966 [00:12<00:00, 156.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CoLA acceptability stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1966/1966 [03:24<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ACC | SIM |  FL  |   J   | BLEU |\n",
      "\n",
      "| --- | --- | ---- |  ---  | ---- |\n",
      "\n",
      "|0.6264|0.7063|0.8224|0.3692|0.4994|\n",
      "\n",
      "running on cuda\n",
      "Calculating style of predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1966/1966 [01:22<00:00, 23.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU similarity\n",
      "Calculating similarity by Wieting subword-embedding SIM model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1966/1966 [00:13<00:00, 146.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CoLA acceptability stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1966/1966 [03:25<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ACC | SIM |  FL  |   J   | BLEU |\n",
      "\n",
      "| --- | --- | ---- |  ---  | ---- |\n",
      "\n",
      "|0.6588|0.7150|0.8290|0.3974|0.5093|\n",
      "\n",
      "running on cuda\n",
      "Calculating style of predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1966/1966 [01:20<00:00, 24.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU similarity\n",
      "Calculating similarity by Wieting subword-embedding SIM model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1966/1966 [00:12<00:00, 162.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CoLA acceptability stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1966/1966 [03:16<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ACC | SIM |  FL  |   J   | BLEU |\n",
      "\n",
      "| --- | --- | ---- |  ---  | ---- |\n",
      "\n",
      "|0.6786|0.7187|0.8311|0.4122|0.5141|\n",
      "\n",
      "running on cuda\n",
      "Calculating style of predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1966/1966 [01:22<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU similarity\n",
      "Calculating similarity by Wieting subword-embedding SIM model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1966/1966 [00:12<00:00, 151.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CoLA acceptability stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1966/1966 [03:23<00:00,  9.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ACC | SIM |  FL  |   J   | BLEU |\n",
      "\n",
      "| --- | --- | ---- |  ---  | ---- |\n",
      "\n",
      "|0.6854|0.7206|0.8320|0.4182|0.5162|\n",
      "\n",
      "running on cuda\n",
      "Calculating style of predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1966/1966 [01:22<00:00, 23.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU similarity\n",
      "Calculating similarity by Wieting subword-embedding SIM model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1966/1966 [00:12<00:00, 157.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CoLA acceptability stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1966/1966 [03:25<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ACC | SIM |  FL  |   J   | BLEU |\n",
      "\n",
      "| --- | --- | ---- |  ---  | ---- |\n",
      "\n",
      "|0.6892|0.7210|0.8325|0.4209|0.5168|\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7865, training_loss=0.2952364815471283, metrics={'train_runtime': 7020.8548, 'train_samples_per_second': 179.189, 'train_steps_per_second': 1.12, 'total_flos': 4.256702668996608e+16, 'train_loss': 0.2952364815471283, 'epoch': 5.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_traindataset['train'],\n",
    "    eval_dataset=tokenized_traindataset['test'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metric\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # saving model\n",
    "trainer.save_model('../models/t5-small-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model and run inference for it\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('../models/t5-small-best')\n",
    "model.eval()\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, inference_request, tokenizer=tokenizer):\n",
    "    input_ids = tokenizer(inference_request, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "    outputs = model.generate(input_ids=input_ids)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 518/518 [03:16<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "target = []\n",
    "for data, label in tqdm(test_dataloader):\n",
    "    out = inference(model, data, tokenizer)\n",
    "    target.extend(label)\n",
    "    outputs.extend(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_hypothesis2 = pd.DataFrame({'Predictions': outputs})\n",
    "predictions_hypothesis2.to_csv('hypothesis2_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on cuda\n",
      "Calculating style of predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 518/518 [00:21<00:00, 23.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU similarity\n",
      "Calculating similarity by Wieting subword-embedding SIM model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 518/518 [00:03<00:00, 159.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CoLA acceptability stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 518/518 [00:55<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ACC | SIM |  FL  |   J   | BLEU |\n",
      "\n",
      "| --- | --- | ---- |  ---  | ---- |\n",
      "\n",
      "|0.6887|0.7233|0.8324|0.4203|0.5192|\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACC': 0.6887157182554066,\n",
       " 'SIM': 0.723305512939735,\n",
       " 'FL': 0.8324346852929216,\n",
       " 'J': 0.4203377930078891,\n",
       " 'BLUE': 0.519224402891123}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metric(target, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
