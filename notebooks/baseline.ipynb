{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline will be classificator + parapharser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24645 entries, 0 to 24644\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   word    24640 non-null  object\n",
      " 1   target  24645 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 577.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../data/interim/words.csv', index_col=0)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in dataset: 24645\n",
      "Unique words in dataset: 12670\n",
      "Nulls: 5\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of words in dataset: {len(data)}')\n",
    "print(f'Unique words in dataset: {len(data[\"word\"].unique())}')\n",
    "print(f'Nulls: {data[\"word\"].isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows without words and duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['word'])\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same Words can be both negative and positive meanings based on context, which is why we categorize them as \"Negative\" to prevent False Positive identifications. This approach can enhance precision scores but may result in a decrease in recall, as it could lead to more instances of False Negatives. For our specific task, this is not particularly crucial, as we have the option to substitute positive words with alternative positive terms.\n",
    "\n",
    "![Alt text](https://www.researchgate.net/publication/336402347/figure/fig3/AS:812472659349505@1570719985505/Calculation-of-Precision-Recall-and-Accuracy-in-the-confusion-matrix.ppm \"a title\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['word'].duplicated(keep=False), 'target'] = 'Negative'\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in dataset: 12669\n",
      "Unique words in dataset: 12669\n",
      "Nulls: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of words in dataset: {len(data)}')\n",
    "print(f'Unique words in dataset: {len(data[\"word\"].unique())}')\n",
    "print(f'Nulls: {data[\"word\"].isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the distribution of target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "target_counts = data['target'].value_counts()\n",
    "target_counts.sort_index()\n",
    "plt.bar(target_counts.index, target_counts.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data['target'] = data['target'].replace({'Positive': 0, 'Negative': 1})\n",
    "X_train, y_train = data['word'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function Preprocessor at 0x29c31ad40&gt;)),\n",
       "                (&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function Preprocessor at 0x29c31ad40&gt;)),\n",
       "                (&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function Preprocessor at 0x29c31ad40&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 FunctionTransformer(func=<function Preprocessor at 0x29c31ad40>)),\n",
       "                ('vectorizer', CountVectorizer()),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def Preprocessor(text):\n",
    "    \n",
    "    if isinstance(text, list):\n",
    "        text = pd.Series(text)\n",
    "\n",
    "    if isinstance(text, pd.core.series.Series):\n",
    "        return text.str.lower().str.strip()\n",
    "    elif isinstance(text, str):\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        text = text.lower()\n",
    "        tokenized = word_tokenize(text)\n",
    "        return tokenized\n",
    "\n",
    "\n",
    "classificator = Pipeline([\n",
    "    ('preprocessor', FunctionTransformer(func=Preprocessor)),\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "classificator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577772</th>\n",
       "      <td>You didn't know that Estelle had stolen some f...</td>\n",
       "      <td>you didn't know that Estelle stole your fish f...</td>\n",
       "      <td>0.870322</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.949143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577773</th>\n",
       "      <td>It'il suck the life out of you!</td>\n",
       "      <td>you'd be sucked out of your life!</td>\n",
       "      <td>0.722897</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.215794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577774</th>\n",
       "      <td>I can't fuckin' take that, bruv.</td>\n",
       "      <td>I really can't take this.</td>\n",
       "      <td>0.617511</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.984538</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577775</th>\n",
       "      <td>They called me a fucking hero. The truth is I ...</td>\n",
       "      <td>they said I was a hero, but I didn't care.</td>\n",
       "      <td>0.679613</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.991945</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577776</th>\n",
       "      <td>I did not screw him.</td>\n",
       "      <td>I didn't fuck him.</td>\n",
       "      <td>0.868475</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.009480</td>\n",
       "      <td>0.994174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>577777 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reference   \n",
       "0       If Alkar is flooding her with psychic waste, t...  \\\n",
       "1                               Now you're getting nasty.   \n",
       "2                Well, we could spare your life, for one.   \n",
       "3               Ah! Monkey, you've got to snap out of it.   \n",
       "4                        I've got orders to put her down.   \n",
       "...                                                   ...   \n",
       "577772  You didn't know that Estelle had stolen some f...   \n",
       "577773                    It'il suck the life out of you!   \n",
       "577774                   I can't fuckin' take that, bruv.   \n",
       "577775  They called me a fucking hero. The truth is I ...   \n",
       "577776                               I did not screw him.   \n",
       "\n",
       "                                              translation  similarity   \n",
       "0       if Alkar floods her with her mental waste, it ...    0.785171  \\\n",
       "1                             you're becoming disgusting.    0.749687   \n",
       "2                           well, we can spare your life.    0.919051   \n",
       "3                            monkey, you have to wake up.    0.664333   \n",
       "4                              I have orders to kill her.    0.726639   \n",
       "...                                                   ...         ...   \n",
       "577772  you didn't know that Estelle stole your fish f...    0.870322   \n",
       "577773                  you'd be sucked out of your life!    0.722897   \n",
       "577774                          I really can't take this.    0.617511   \n",
       "577775         they said I was a hero, but I didn't care.    0.679613   \n",
       "577776                                 I didn't fuck him.    0.868475   \n",
       "\n",
       "        lenght_diff   ref_tox   trn_tox  \n",
       "0          0.010309  0.014195  0.981983  \n",
       "1          0.071429  0.065473  0.999039  \n",
       "2          0.268293  0.213313  0.985068  \n",
       "3          0.309524  0.053362  0.994215  \n",
       "4          0.181818  0.009402  0.999348  \n",
       "...             ...       ...       ...  \n",
       "577772     0.030769  0.000121  0.949143  \n",
       "577773     0.058824  0.996124  0.215794  \n",
       "577774     0.212121  0.984538  0.000049  \n",
       "577775     0.358209  0.991945  0.000124  \n",
       "577776     0.095238  0.009480  0.994174  \n",
       "\n",
       "[577777 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_data = pd.read_csv('../data/raw/filtered.tsv', sep='\\t', index_col=0)\n",
    "detox_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 577777 entries, 0 to 577776\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   reference    577777 non-null  object \n",
      " 1   translation  577777 non-null  object \n",
      " 2   similarity   577777 non-null  float64\n",
      " 3   lenght_diff  577777 non-null  float64\n",
      " 4   ref_tox      577777 non-null  float64\n",
      " 5   trn_tox      577777 non-null  float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 30.9+ MB\n"
     ]
    }
   ],
   "source": [
    "detox_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm not gonna have a child... ...with the same...</td>\n",
       "      <td>I'm not going to breed kids with a genetic dis...</td>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.950956</td>\n",
       "      <td>0.035846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>They're all laughing at us, so we'll kick your...</td>\n",
       "      <td>they're laughing at us. We'll show you.</td>\n",
       "      <td>0.618866</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Maine was very short on black people back then.</td>\n",
       "      <td>there wasn't much black in Maine then.</td>\n",
       "      <td>0.720482</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>0.148710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>So now their spirits are cursed, walking back ...</td>\n",
       "      <td>their souls are cursed, they guard the paths, ...</td>\n",
       "      <td>0.755883</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.842509</td>\n",
       "      <td>0.143992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Come on, Cal, leave that shit alone.</td>\n",
       "      <td>come on, Cal, put it down.</td>\n",
       "      <td>0.660481</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.999637</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577770</th>\n",
       "      <td>I am so crazy nuts about you guys.</td>\n",
       "      <td>I'm so crazy about you guys.</td>\n",
       "      <td>0.934512</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.973442</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577771</th>\n",
       "      <td>I thought American men were bad enough, but no...</td>\n",
       "      <td>an American man is worth nothing, but for you,...</td>\n",
       "      <td>0.671444</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>0.035941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577773</th>\n",
       "      <td>It'il suck the life out of you!</td>\n",
       "      <td>you'd be sucked out of your life!</td>\n",
       "      <td>0.722897</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.215794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577774</th>\n",
       "      <td>I can't fuckin' take that, bruv.</td>\n",
       "      <td>I really can't take this.</td>\n",
       "      <td>0.617511</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.984538</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577775</th>\n",
       "      <td>They called me a fucking hero. The truth is I ...</td>\n",
       "      <td>they said I was a hero, but I didn't care.</td>\n",
       "      <td>0.679613</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.991945</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319142 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reference   \n",
       "5       I'm not gonna have a child... ...with the same...  \\\n",
       "6       They're all laughing at us, so we'll kick your...   \n",
       "7         Maine was very short on black people back then.   \n",
       "11      So now their spirits are cursed, walking back ...   \n",
       "13                   Come on, Cal, leave that shit alone.   \n",
       "...                                                   ...   \n",
       "577770                 I am so crazy nuts about you guys.   \n",
       "577771  I thought American men were bad enough, but no...   \n",
       "577773                    It'il suck the life out of you!   \n",
       "577774                   I can't fuckin' take that, bruv.   \n",
       "577775  They called me a fucking hero. The truth is I ...   \n",
       "\n",
       "                                              translation  similarity   \n",
       "5       I'm not going to breed kids with a genetic dis...    0.703185  \\\n",
       "6                 they're laughing at us. We'll show you.    0.618866   \n",
       "7                  there wasn't much black in Maine then.    0.720482   \n",
       "11      their souls are cursed, they guard the paths, ...    0.755883   \n",
       "13                             come on, Cal, put it down.    0.660481   \n",
       "...                                                   ...         ...   \n",
       "577770                       I'm so crazy about you guys.    0.934512   \n",
       "577771  an American man is worth nothing, but for you,...    0.671444   \n",
       "577773                  you'd be sucked out of your life!    0.722897   \n",
       "577774                          I really can't take this.    0.617511   \n",
       "577775         they said I was a hero, but I didn't care.    0.679613   \n",
       "\n",
       "        lenght_diff   ref_tox   trn_tox  \n",
       "5          0.206522  0.950956  0.035846  \n",
       "6          0.230769  0.999492  0.000131  \n",
       "7          0.187500  0.963680  0.148710  \n",
       "11         0.013245  0.842509  0.143992  \n",
       "13         0.270270  0.999637  0.000279  \n",
       "...             ...       ...       ...  \n",
       "577770     0.171429  0.973442  0.000709  \n",
       "577771     0.371212  0.999624  0.035941  \n",
       "577773     0.058824  0.996124  0.215794  \n",
       "577774     0.212121  0.984538  0.000049  \n",
       "577775     0.358209  0.991945  0.000124  \n",
       "\n",
       "[319142 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_data = detox_data[detox_data['ref_tox'] >= detox_data['trn_tox']]\n",
    "detox_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/adautov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adautov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def paraphraser(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def get_synonym_by_context(word, context_sentence):\n",
    "        # Disambiguate the word in the context sentence\n",
    "        sense = lesk(context_sentence, word)\n",
    "\n",
    "        # Find synonyms for the disambiguated sense\n",
    "        synonyms = []\n",
    "        if sense:\n",
    "            for lemma in sense.lemmas():\n",
    "                synonyms.append(lemma.name().replace('_', ' '))\n",
    "\n",
    "        # Remove duplicates and display the closest synonym\n",
    "        synonyms = list(set(synonyms))\n",
    "        if len(synonyms) == 0:\n",
    "            synonyms.append(word)\n",
    "        #rearrange synonyms by they toxicity\n",
    "        synonyms = sorted([(synonym, classificator.predict_proba(synonym)[0, 1]) for synonym in synonyms], key= lambda x: x[1])\n",
    "        return synonyms[0][0]\n",
    "\n",
    "    tokenized = Preprocessor(sentence)\n",
    "    predictions = classificator.predict(tokenized)\n",
    "    mask = np.array([0 if word in stop_words else 1 for word in tokenized])\n",
    "    predictions = predictions * mask\n",
    "    assert len(predictions) == len(tokenized)\n",
    "    paraphrased = [get_synonym_by_context(word, sentence) if predictions[i] == 1 else word for i, word in enumerate(tokenized)]\n",
    "    return ' '.join(paraphrased)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = detox_data['reference'].iloc[:1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not gonna have a child... ...with the same genetic disorder as me who's gonna die. L...\n",
      "im not gon sodium have a child with the same genetical disorderliness as me World Health Organization gon sodium die cubic decimeter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(sentence, paraphraser(sentence), end='\\n\\n',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They're all laughing at us, so we'll kick your ass.\n",
      "Pred: theyre all laughing at uranium so well kick your ass\n",
      "True: they're laughing at us. We'll show you.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/metric')\n",
    "from metric import calculate_metric\n",
    "\n",
    "N = 100\n",
    "X, y_true = detox_data['reference'].values[:N], detox_data['translation'].values[:N]\n",
    "\n",
    "print(X[1])\n",
    "print(f'Pred: {paraphraser(X[1])}\\nTrue: {y_true[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "for sentence in X:\n",
    "   y_preds.append(paraphraser(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating style of predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.36it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU similarity\n",
      "Calculating similarity by Wieting subword-embedding SIM model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 221.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CoLA acceptability stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ACC | SIM |  FL  |   J   | BLEU |\n",
      "\n",
      "| --- | --- | ---- |  ---  | ---- |\n",
      "\n",
      "|0.6500|0.5319|0.9400|0.3291|0.3953|\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.65, 0.5318588982522487, 0.94, 0.3291400098800659, 0.3953042070502675)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metric(y_true, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
